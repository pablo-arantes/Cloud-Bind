{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pablo-arantes/Cloud-Bind/blob/main/Boltz_GNINA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bsZLJrYy46Wm",
      "metadata": {
        "id": "bsZLJrYy46Wm"
      },
      "source": [
        "# **Hi there!**\n",
        "\n",
        "This notebook is part of **Cloud-Bind** and provides an end-to-end workflow for **protein–ligand structure prediction + docking** in Google Colab.\n",
        "\n",
        "The main goal is to show how cloud compute can be used to run an accessible structure-based pipeline for **co-folding** and **re-docking**.\n",
        "\n",
        "---\n",
        "\n",
        "**This notebook is NOT a standard protocol for docking or scoring.** It is an instructional pipeline meant to illustrate common steps and a practical stack in a Colab setting.\n",
        "\n",
        "**Runtime Note**: A **GPU runtime is strongly recommended**. CPU runs can be extremely slow for Boltz-2.\n",
        "\n",
        "---\n",
        "\n",
        "**Bugs**\n",
        "- If you encounter any bugs, please report the issue to https://github.com/pablo-arantes/Cloud-Bind/issues\n",
        "\n",
        "**Acknowledgments**\n",
        "- **Core Pipeline**: We thank the developers of [Boltz](https://github.com/jwohlwend/boltz) (structure prediction), [ColabFold](https://github.com/sokrypton/ColabFold) (MSA server), [P2Rank](https://github.com/rdk/p2rank) (pocket detection), and [GNINA](https://github.com/gnina/gnina) (docking/scoring).\n",
        "- **Cheminformatics & QC**: We thank the teams behind [Open Babel](https://github.com/openbabel/openbabel) (conversion), [RDKit](https://github.com/rdkit/rdkit) (ligand handling), [Dimorphite-DL](https://github.com/durrantlab/dimorphite_dl) (protonation), [PoseBusters](https://github.com/maabuu/posebusters) (QC), [ProLIF](https://github.com/chemosim-lab/ProLIF) (interactions), [MDAnalysis](https://github.com/MDAnalysis/mdanalysis) (parsing), and [Biopython](https://github.com/biopython/biopython).\n",
        "- **Visualization & Runtime**: Credit to [py3Dmol](https://3dmol.csb.pitt.edu/) for visualization and [PyTorch](https://github.com/pytorch/pytorch) for runtime dependencies.\n",
        "- **Cloud-Bind Team**: **Pablo R. Arantes** ([@pablitoarantes](https://twitter.com/pablitoarantes)), **Conrado Pedebos** ([@ConradoPedebos](https://twitter.com/ConradoPedebos)), **Rodrigo Ligabue-Braun** ([@ligabue_braun](https://twitter.com/ligabue_braun)), **Davidt da Silva Tarouco**, and **Saul J. Flores** ([@saulfloresjr](https://www.linkedin.com/in/saulfloresjr/)).\n",
        "\n",
        "- For related notebooks see: [Cloud-Bind](https://github.com/pablo-arantes/Cloud-Bind)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "shR8vnny46Wn",
      "metadata": {
        "id": "shR8vnny46Wn"
      },
      "source": [
        "## **A. Runtime & project folder**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "B0nlvDCk46Wo",
      "metadata": {
        "cellView": "form",
        "id": "B0nlvDCk46Wo"
      },
      "outputs": [],
      "source": [
        "#@title **A1) Initialize project folders**\n",
        "\n",
        "from pathlib import Path\n",
        "import os, json, datetime\n",
        "\n",
        "# ----------------------------\n",
        "# Project naming\n",
        "# ----------------------------\n",
        "PROJECT_NAME = \"\"  #@param {type:\"string\"}\n",
        "PROJECT_ROOT = Path(f\"/content/{PROJECT_NAME}\")\n",
        "\n",
        "TOOLS_DIR = Path(\"/content/cloudbind_tools\")\n",
        "\n",
        "RUNS_DIR = PROJECT_ROOT / \"runs\"\n",
        "\n",
        "INSTALL_LOGS_DIR = PROJECT_ROOT / \"logs\"   # installs / environment\n",
        "# Per-run logs live in: runs/<run_name>/logs/\n",
        "\n",
        "# ----------------------------\n",
        "# Create folders\n",
        "# ----------------------------\n",
        "for p in [PROJECT_ROOT, TOOLS_DIR, RUNS_DIR, INSTALL_LOGS_DIR]:\n",
        "    p.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "os.environ[\"PATH\"] = f\"{TOOLS_DIR}:{os.environ.get('PATH','')}\"\n",
        "\n",
        "# bootstrap\n",
        "BOOTSTRAP_PATH = Path(\"/content/.cloudbind_bootstrap.json\")\n",
        "bootstrap = {\n",
        "    \"created_at\": datetime.datetime.now().isoformat(),\n",
        "    \"project_name\": PROJECT_NAME,\n",
        "    \"project_root\": str(PROJECT_ROOT),\n",
        "    \"runs_dir\": str(RUNS_DIR),\n",
        "    \"install_logs_dir\": str(INSTALL_LOGS_DIR),\n",
        "    \"tools_dir\": str(TOOLS_DIR),\n",
        "}\n",
        "BOOTSTRAP_PATH.write_text(json.dumps(bootstrap, indent=2))\n",
        "\n",
        "print(f\"Project root : {PROJECT_ROOT}\")\n",
        "print(f\"Runs dir     : {RUNS_DIR}\")\n",
        "print(f\"Tools dir    : {TOOLS_DIR}  (excluded from export zip)\")\n",
        "print(f\"Install logs : {INSTALL_LOGS_DIR}\")\n",
        "print(f\"Bootstrap    : {BOOTSTRAP_PATH}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QkCZs-GQ46Wp",
      "metadata": {
        "id": "QkCZs-GQ46Wp"
      },
      "source": [
        "## **B. Install Dependencies**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xHFZy5fU46Wq",
      "metadata": {
        "cellView": "form",
        "id": "xHFZy5fU46Wq"
      },
      "outputs": [],
      "source": [
        "#@title **B1) Install Boltz-2, P2Rank, GNINA, and analysis tools**\n",
        "\n",
        "#@markdown Once this cell triggers a runtime restart, **run it again once** after the restart to finish installation.\n",
        "\n",
        "import os, subprocess, json, sys, shlex\n",
        "from pathlib import Path\n",
        "\n",
        "# rehydrate paths\n",
        "BOOTSTRAP_PATH = Path(\"/content/.cloudbind_bootstrap.json\")\n",
        "if \"INSTALL_LOGS_DIR\" not in globals() and BOOTSTRAP_PATH.exists():\n",
        "    _boot = json.loads(BOOTSTRAP_PATH.read_text())\n",
        "    INSTALL_LOGS_DIR = Path(_boot.get(\"install_logs_dir\", \"/content/cloudbind_project/logs\"))\n",
        "    INSTALL_LOGS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# --------- pinned versions (edit if needed) ----------\n",
        "BOLTZ_VERSION  = \"2.2.1\"\n",
        "P2RANK_VERSION = \"2.5.1\"\n",
        "GNINA_VERSION  = \"1.3.2\"\n",
        "\n",
        "TOOLS_DIR = Path(\"/content/cloudbind_tools\")\n",
        "TOOLS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "os.environ[\"PATH\"] = f\"{TOOLS_DIR}:{os.environ.get('PATH','')}\"\n",
        "\n",
        "install_log = INSTALL_LOGS_DIR / \"01_install.log\"\n",
        "stamp_path  = TOOLS_DIR / f\"install_stamp_boltz{BOLTZ_VERSION}_p2rank{P2RANK_VERSION}_gnina{GNINA_VERSION}.json\"\n",
        "post_restart_flag = TOOLS_DIR / \".post_install_restart_done\"\n",
        "\n",
        "def _tail(path: Path, n=60):\n",
        "    if not path.exists():\n",
        "        return \"\"\n",
        "    lines = path.read_text(errors=\"ignore\").splitlines()\n",
        "    return \"\\n\".join(lines[-n:])\n",
        "\n",
        "def run_cmd(cmd: str, log_path: Path, cwd: Path | None = None):\n",
        "    log_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    with log_path.open(\"a\") as f:\n",
        "        f.write(f\"\\n\\n$ {cmd}\\n\")\n",
        "        p = subprocess.run(cmd, shell=True, cwd=str(cwd) if cwd else None,\n",
        "                           stdout=f, stderr=subprocess.STDOUT, text=True)\n",
        "    if p.returncode != 0:\n",
        "        raise RuntimeError(f\"Command failed: {cmd}\\n\\n--- tail({log_path}) ---\\n{_tail(log_path)}\")\n",
        "\n",
        "def have_file(path: Path) -> bool:\n",
        "    return path.exists() and path.is_file()\n",
        "\n",
        "# ----------------------------\n",
        "# Detect runtime\n",
        "# ----------------------------\n",
        "def detect_runtime():\n",
        "    if os.environ.get(\"COLAB_TPU_ADDR\"):\n",
        "        return \"TPU\"\n",
        "    try:\n",
        "        import torch\n",
        "        if torch.cuda.is_available():\n",
        "            return f\"GPU ({torch.cuda.get_device_name(0)})\"\n",
        "    except Exception:\n",
        "        pass\n",
        "    return \"CPU\"\n",
        "\n",
        "runtime = detect_runtime()\n",
        "print(f\"Runtime detected: {runtime}\")\n",
        "if \"CPU\" in runtime or \"TPU\" in runtime:\n",
        "    print(\"Note: Boltz-2 protein-ligand inference is strongly recommended on GPU for speed.\")\n",
        "\n",
        "# ----------------------------\n",
        "# Skip if already installed\n",
        "# ----------------------------\n",
        "p2rank_dir = TOOLS_DIR / f\"p2rank_{P2RANK_VERSION}\"\n",
        "p2rank_prank = p2rank_dir / \"prank\"\n",
        "gnina_bin = TOOLS_DIR / \"gnina\"\n",
        "\n",
        "did_install = False\n",
        "if stamp_path.exists() and have_file(gnina_bin) and have_file(p2rank_prank):\n",
        "    print(\"Existing installation detected (stamp found). Skipping re-install.\")\n",
        "else:\n",
        "    did_install = True\n",
        "\n",
        "    # --------- system deps ----------\n",
        "    run_cmd(\"apt-get -qq update\", install_log)\n",
        "    run_cmd(\"apt-get -qq install -y openjdk-17-jre-headless wget unzip tar rsync\", install_log)\n",
        "\n",
        "    # Open Babel\n",
        "    run_cmd(\"apt-get -qq install -y openbabel\", install_log)\n",
        "\n",
        "    # --------- python deps ----------\n",
        "    try:\n",
        "        import torch\n",
        "        has_cuda = torch.cuda.is_available()\n",
        "    except Exception:\n",
        "        has_cuda = False\n",
        "\n",
        "    boltz_spec = f\"boltz[cuda]=={BOLTZ_VERSION}\" if has_cuda else f\"boltz=={BOLTZ_VERSION}\"\n",
        "\n",
        "    # avoid pip upgrade\n",
        "    run_cmd(f\"python -m pip -q install '{boltz_spec}'\", install_log)\n",
        "\n",
        "    # viz and qc stack\n",
        "    run_cmd(\"python -m pip -q install py3Dmol prolif posebusters MDAnalysis rdkit dimorphite-dl biopython\", install_log)\n",
        "\n",
        "    # --------- GNINA binary ----------\n",
        "    run_cmd(f\"wget -q -O {gnina_bin} https://github.com/gnina/gnina/releases/download/v{GNINA_VERSION}/gnina.{GNINA_VERSION}\", install_log)\n",
        "    run_cmd(f\"chmod +x {gnina_bin}\", install_log)\n",
        "\n",
        "    # --------- P2Rank release ----------\n",
        "    p2rank_tar = TOOLS_DIR / f\"p2rank_{P2RANK_VERSION}.tar.gz\"\n",
        "    run_cmd(f\"wget -q -O {p2rank_tar} https://github.com/rdk/p2rank/releases/download/{P2RANK_VERSION}/p2rank_{P2RANK_VERSION}.tar.gz\", install_log)\n",
        "    run_cmd(f\"tar -xzf {p2rank_tar} -C {TOOLS_DIR}\", install_log)\n",
        "\n",
        "    # validate prank exists\n",
        "    if not p2rank_prank.exists():\n",
        "        raise RuntimeError(f\"P2Rank installed but prank entrypoint not found at: {p2rank_prank}\\nCheck install log: {install_log}\")\n",
        "\n",
        "    # write stamp\n",
        "    stamp = {\n",
        "        \"timestamp\": __import__(\"datetime\").datetime.now().isoformat(),\n",
        "        \"boltz\": BOLTZ_VERSION,\n",
        "        \"p2rank\": P2RANK_VERSION,\n",
        "        \"gnina\": GNINA_VERSION,\n",
        "        \"runtime\": runtime,\n",
        "        \"tools_dir\": str(TOOLS_DIR),\n",
        "        \"gnina_path\": str(gnina_bin),\n",
        "        \"p2rank_dir\": str(p2rank_dir),\n",
        "        \"p2rank_prank\": str(p2rank_prank),\n",
        "    }\n",
        "    stamp_path.write_text(json.dumps(stamp, indent=2))\n",
        "\n",
        "# update bootstrap\n",
        "BOOTSTRAP_PATH = Path(\"/content/.cloudbind_bootstrap.json\")\n",
        "if BOOTSTRAP_PATH.exists():\n",
        "    boot = json.loads(BOOTSTRAP_PATH.read_text())\n",
        "else:\n",
        "    boot = {}\n",
        "\n",
        "boot.update({\n",
        "    \"boltz_version\": BOLTZ_VERSION,\n",
        "    \"p2rank_version\": P2RANK_VERSION,\n",
        "    \"gnina_version\": GNINA_VERSION,\n",
        "    \"tools_dir\": str(TOOLS_DIR),\n",
        "    \"gnina_path\": str(gnina_bin),\n",
        "    \"p2rank_dir\": str(p2rank_dir),\n",
        "    \"p2rank_prank\": str(p2rank_prank),\n",
        "    \"install_stamp\": str(stamp_path),\n",
        "})\n",
        "BOOTSTRAP_PATH.write_text(json.dumps(boot, indent=2))\n",
        "\n",
        "print(\"Installed. Key tools:\")\n",
        "print(f\"  boltz  : {BOLTZ_VERSION}\")\n",
        "print(f\"  gnina  : {GNINA_VERSION}  -> {gnina_bin}\")\n",
        "print(f\"  p2rank : {P2RANK_VERSION} -> {p2rank_prank}\")\n",
        "print(f\"Install log: {install_log}\")\n",
        "print(f\"Bootstrap: {BOOTSTRAP_PATH}\")\n",
        "\n",
        "# ----------------------------\n",
        "# One-time post-install restart\n",
        "# ----------------------------\n",
        "if did_install and not post_restart_flag.exists():\n",
        "    post_restart_flag.write_text(\"ok\")\n",
        "    print(\"\\nColab: restarting runtime once to finalize binary wheels (prevents numpy/pandas ABI errors).\")\n",
        "    os.kill(os.getpid(), 9)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "crGrRp4Y46Wq",
      "metadata": {
        "id": "crGrRp4Y46Wq"
      },
      "source": [
        "### **Shared helpers**\n",
        "\n",
        "Logging and small display utilities used throughout the notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VTP8BrMj46Wq",
      "metadata": {
        "cellView": "form",
        "id": "VTP8BrMj46Wq"
      },
      "outputs": [],
      "source": [
        "#@title **Helpers**\n",
        "\n",
        "import subprocess, warnings, json, os\n",
        "from pathlib import Path\n",
        "\n",
        "# ----------------------------\n",
        "# Rehydrate bootstrap (lets you continue after the one-time install restart)\n",
        "# ----------------------------\n",
        "BOOTSTRAP_PATH = Path(\"/content/.cloudbind_bootstrap.json\")\n",
        "if BOOTSTRAP_PATH.exists():\n",
        "    _boot = json.loads(BOOTSTRAP_PATH.read_text())\n",
        "    PROJECT_NAME = _boot.get(\"project_name\", \"cloudbind_project\")\n",
        "    PROJECT_ROOT = Path(_boot.get(\"project_root\", f\"/content/{PROJECT_NAME}\"))\n",
        "    RUNS_DIR = Path(_boot.get(\"runs_dir\", str(PROJECT_ROOT / \"runs\")))\n",
        "    INSTALL_LOGS_DIR = Path(_boot.get(\"install_logs_dir\", str(PROJECT_ROOT / \"logs\")))\n",
        "    TOOLS_DIR = Path(_boot.get(\"tools_dir\", \"/content/cloudbind_tools\"))\n",
        "\n",
        "    # version check\n",
        "    BOLTZ_VERSION  = _boot.get(\"boltz_version\")\n",
        "    P2RANK_VERSION = _boot.get(\"p2rank_version\")\n",
        "    GNINA_VERSION  = _boot.get(\"gnina_version\")\n",
        "else:\n",
        "    raise FileNotFoundError(\"Bootstrap file not found. Run A1 once to initialize the project.\")\n",
        "\n",
        "os.environ[\"PATH\"] = f\"{TOOLS_DIR}:{os.environ.get('PATH','')}\"\n",
        "\n",
        "# load version if missing\n",
        "if not (BOLTZ_VERSION and P2RANK_VERSION and GNINA_VERSION):\n",
        "    stamp_files = sorted(TOOLS_DIR.glob(\"install_stamp_*.json\"))\n",
        "    if stamp_files:\n",
        "        stamp = json.loads(stamp_files[-1].read_text())\n",
        "        BOLTZ_VERSION  = BOLTZ_VERSION  or stamp.get(\"boltz\")\n",
        "        P2RANK_VERSION = P2RANK_VERSION or stamp.get(\"p2rank\")\n",
        "        GNINA_VERSION  = GNINA_VERSION  or stamp.get(\"gnina\")\n",
        "\n",
        "try:\n",
        "    import pandas as pd\n",
        "except ValueError as e:\n",
        "    if \"numpy.dtype size changed\" in str(e):\n",
        "        print(\"=\"*60)\n",
        "        print(\"BINARY INCOMPATIBILITY DETECTED (numpy/pandas)\")\n",
        "        print(\"Fix: Runtime -> Restart session, then run Helpers and continue.\")\n",
        "        print(\"=\"*60)\n",
        "    raise e\n",
        "\n",
        "# ----------------------------\n",
        "# logging control\n",
        "# ----------------------------\n",
        "warnings.filterwarnings(\"ignore\", message=r\"netCDF4 is not available.*\")\n",
        "warnings.filterwarnings(\"ignore\", message=r\"Unit cell dimensions not found.*\")\n",
        "warnings.filterwarnings(\"ignore\", message=r\".*CRYST1 record.*\")\n",
        "warnings.filterwarnings(\"ignore\", message=r\"Found no information for attr: 'formalcharges'.*\")\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning, message=r\"MDAnalysis\\.topology\\.tables.*\")\n",
        "\n",
        "# rdkit warning logging\n",
        "try:\n",
        "    from rdkit import RDLogger\n",
        "    RDLogger.DisableLog(\"rdApp.warning\")\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# mda logging\n",
        "import logging\n",
        "logging.getLogger(\"MDAnalysis\").setLevel(logging.ERROR)\n",
        "logging.getLogger(\"MDAnalysis.coordinates.AMBER\").setLevel(logging.ERROR)\n",
        "\n",
        "def tail(path: Path, n=60) -> str:\n",
        "    if not path.exists():\n",
        "        return \"\"\n",
        "    lines = path.read_text(errors=\"ignore\").splitlines()\n",
        "    return \"\\n\".join(lines[-n:])\n",
        "\n",
        "def run_cmd(cmd: str, log_path: Path, cwd: Path | None = None):\n",
        "    \"\"\"Run a shell command quietly; append stdout/stderr to log_path.\"\"\"\n",
        "    log_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    with log_path.open(\"a\") as f:\n",
        "        f.write(f\"\\n\\n$ {cmd}\\n\")\n",
        "        p = subprocess.run(cmd, shell=True, cwd=str(cwd) if cwd else None,\n",
        "                           stdout=f, stderr=subprocess.STDOUT, text=True)\n",
        "    if p.returncode != 0:\n",
        "        raise RuntimeError(f\"Command failed: {cmd}\\n\\n--- tail({log_path}) ---\\n{tail(log_path)}\")\n",
        "\n",
        "def show_table(df: pd.DataFrame, max_rows=10):\n",
        "    \"\"\"Display a compact table without spamming the notebook.\"\"\"\n",
        "    from IPython.display import display\n",
        "    display(df.head(max_rows))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "FumcftNP46Wq",
      "metadata": {
        "id": "FumcftNP46Wq"
      },
      "source": [
        "## **C. Inputs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "k_9TqWCQ46Wq",
      "metadata": {
        "cellView": "form",
        "id": "k_9TqWCQ46Wq"
      },
      "outputs": [],
      "source": [
        "#@title **C1) Inputs + Boltz preset**\n",
        "#@markdown Required inputs.\n",
        "\n",
        "RUN_NAME = \"\"  #@param {type:\"string\"}\n",
        "# clear testing inputs\n",
        "PROTEIN_SEQUENCE = \"\"  #@param {type:\"string\"}\n",
        "LIGAND_SMILES = \"\"  #@param {type:\"string\"}\n",
        "\n",
        "#@markdown **Boltz preset**\n",
        "#@markdown - Fast: Demo / Testing, fewer sampling\n",
        "#@markdown - Standard: Default, moderate sampling\n",
        "#@markdown - Quality: Refinement, more sampling\n",
        "\n",
        "\n",
        "BOLTZ_PRESET = \"Fast\"  #@param [\"Fast\",\"Standard\",\"Quality\"]\n",
        "\n",
        "from pathlib import Path\n",
        "import json\n",
        "\n",
        "RUN_DIR = RUNS_DIR / RUN_NAME\n",
        "for sub in [\"inputs\",\"boltz\",\"p2rank\",\"gnina\",\"analysis\",\"viz\",\"logs\",\"state\",\"export\"]:\n",
        "    (RUN_DIR / sub).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# basic run settings\n",
        "settings = {\n",
        "    \"run_name\": RUN_NAME,\n",
        "    \"boltz_preset\": BOLTZ_PRESET,\n",
        "}\n",
        "(RUN_DIR / \"state\" / \"run_settings.json\").write_text(json.dumps(settings, indent=2))\n",
        "\n",
        "print(f\"Run folder: {RUN_DIR}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7DK34A6746Wq",
      "metadata": {
        "id": "7DK34A6746Wq"
      },
      "source": [
        "## **D. Boltz-2: predict the complex**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nLi5Vuvu46Wr",
      "metadata": {
        "cellView": "form",
        "id": "nLi5Vuvu46Wr"
      },
      "outputs": [],
      "source": [
        "#@title **D1) Run Boltz-2**\n",
        "\n",
        "import json, os, re\n",
        "from pathlib import Path\n",
        "\n",
        "# ---- Torch 2.6+ compatibility: allow OmegaConf DictConfig in trusted checkpoints ----\n",
        "try:\n",
        "    import torch, omegaconf\n",
        "    torch.serialization.add_safe_globals([omegaconf.dictconfig.DictConfig])\n",
        "except Exception as e:\n",
        "    print(f\"(torch safe-globals setup skipped: {e})\")\n",
        "\n",
        "# ---- sanitize inputs ----\n",
        "seq = re.sub(r\"\\s+\", \"\", PROTEIN_SEQUENCE.strip().upper())\n",
        "if not seq:\n",
        "    raise ValueError(\"Please paste a real PROTEIN_SEQUENCE (1-letter amino acids).\")\n",
        "\n",
        "smiles = LIGAND_SMILES.strip()\n",
        "if not smiles:\n",
        "    raise ValueError(\"Please provide a LIGAND_SMILES string.\")\n",
        "\n",
        "# ---- write Boltz YAML input (auto) ----\n",
        "yaml_path = RUN_DIR / \"boltz\" / f\"{RUN_NAME}.yaml\"\n",
        "yaml_text = f\"\"\"version: 1\n",
        "sequences:\n",
        "  - protein:\n",
        "      id: A\n",
        "      sequence: \"{seq}\"\n",
        "  - ligand:\n",
        "      id: L\n",
        "      smiles: \"{smiles}\"\n",
        "properties:\n",
        "  - affinity:\n",
        "      binder: L\n",
        "\"\"\"\n",
        "yaml_path.write_text(yaml_text)\n",
        "\n",
        "# ---- runtime preset mapping ----\n",
        "# Defaults in boltz docs are ~recycling_steps=3, sampling_steps=200 (slower, higher quality).\n",
        "# We expose simplified presets for teaching/training.\n",
        "\n",
        "if BOLTZ_PRESET == \"Fast\":\n",
        "    params = {\n",
        "        \"recycling_steps\": 1,\n",
        "        \"sampling_steps\": 25,\n",
        "        \"diffusion_samples\": 1,\n",
        "        \"sampling_steps_affinity\": 25,\n",
        "        \"diffusion_samples_affinity\": 1,\n",
        "        \"step_scale\": 1.6,\n",
        "        \"max_msa_seqs\": 1024,\n",
        "        \"num_subsampled_msa\": 128,\n",
        "        \"subsample_msa\": True\n",
        "    }\n",
        "elif BOLTZ_PRESET == \"Standard\":\n",
        "    params = {\n",
        "        \"recycling_steps\": 3,\n",
        "        \"sampling_steps\": 200,\n",
        "        \"diffusion_samples\": 1,\n",
        "        \"sampling_steps_affinity\": 200,\n",
        "        \"diffusion_samples_affinity\": 5,\n",
        "        \"step_scale\": 1.638,\n",
        "        \"max_msa_seqs\": 8192,\n",
        "        \"num_subsampled_msa\": 1024,\n",
        "        \"subsample_msa\": False\n",
        "    }\n",
        "else:  # Quality\n",
        "    params = {\n",
        "        \"recycling_steps\": 5,\n",
        "        \"sampling_steps\": 300,\n",
        "        \"diffusion_samples\": 2,\n",
        "        \"sampling_steps_affinity\": 300,\n",
        "        \"diffusion_samples_affinity\": 10,\n",
        "        \"step_scale\": 1.638,\n",
        "        \"max_msa_seqs\": 8192,\n",
        "        \"num_subsampled_msa\": 1024,\n",
        "        \"subsample_msa\": False\n",
        "    }\n",
        "\n",
        "(RUN_DIR / \"state\" / \"boltz_params.json\").write_text(json.dumps(params, indent=2))\n",
        "\n",
        "# Determine accelerator\n",
        "try:\n",
        "    import torch\n",
        "    if torch.cuda.is_available():\n",
        "        accel = \"gpu\"\n",
        "    else:\n",
        "        accel = \"cpu\"\n",
        "except Exception:\n",
        "    accel = \"cpu\"\n",
        "\n",
        "# TPU is not supported for this pipeline\n",
        "if \"COLAB_TPU_ADDR\" in os.environ or \"TPU_NAME\" in os.environ:\n",
        "    raise RuntimeError(\"TPU runtime detected. Please switch to a GPU runtime.\")\n",
        "\n",
        "if accel != \"gpu\":\n",
        "    print(\"Note: GPU strongly recommended. CPU runs can be very slow for real systems.\")\n",
        "\n",
        "out_dir = RUN_DIR / \"boltz\" / \"out\"\n",
        "out_dir.mkdir(exist_ok=True)\n",
        "\n",
        "boltz_log = RUN_DIR / \"logs\" / \"02_boltz.log\"\n",
        "\n",
        "cmd_parts = [\n",
        "    \"boltz predict\",\n",
        "    str(yaml_path),\n",
        "    f\"--out_dir {out_dir}\",\n",
        "    \"--use_msa_server\",\n",
        "    f\"--accelerator {accel}\",\n",
        "    \"--devices 1\",\n",
        "    f\"--recycling_steps {int(params['recycling_steps'])}\",\n",
        "    f\"--sampling_steps {int(params['sampling_steps'])}\",\n",
        "    f\"--diffusion_samples {int(params['diffusion_samples'])}\",\n",
        "    f\"--step_scale {float(params['step_scale'])}\",\n",
        "    f\"--sampling_steps_affinity {int(params['sampling_steps_affinity'])}\",\n",
        "    f\"--diffusion_samples_affinity {int(params['diffusion_samples_affinity'])}\",\n",
        "    \"--output_format pdb\",\n",
        "]\n",
        "\n",
        "# MSA limiting (still uses the MSA server)\n",
        "if params.get(\"subsample_msa\", False):\n",
        "    cmd_parts += [\n",
        "        \"--subsample_msa\",\n",
        "        f\"--num_subsampled_msa {int(params['num_subsampled_msa'])}\",\n",
        "        f\"--max_msa_seqs {int(params['max_msa_seqs'])}\",\n",
        "    ]\n",
        "\n",
        "cmd = \" \".join(cmd_parts)\n",
        "run_cmd(cmd, boltz_log)\n",
        "\n",
        "print(\"Boltz complete.\")\n",
        "print(f\"  Preset: {BOLTZ_PRESET}\")\n",
        "print(f\"  YAML  : {yaml_path}\")\n",
        "print(f\"  Out   : {out_dir}\")\n",
        "print(f\"  Log   : {boltz_log}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b_YnbwZB46Wr",
      "metadata": {
        "cellView": "form",
        "id": "b_YnbwZB46Wr"
      },
      "outputs": [],
      "source": [
        "#@title **D2) Extract receptor, Boltz pose, and affinity**\n",
        "#@markdown Temperature is for conversion only.\n",
        "\n",
        "TEMPERATURE_K = 298.15  #@param {type:\"number\"}\n",
        "\n",
        "import json, math, shutil\n",
        "from pathlib import Path\n",
        "import MDAnalysis as mda\n",
        "\n",
        "out_dir = RUN_DIR / \"boltz\" / \"out\"\n",
        "\n",
        "# --- locate model file ---\n",
        "pdb_candidates = list(out_dir.rglob(\"*_model_0.pdb\")) + list(out_dir.rglob(\"*model_0.pdb\"))\n",
        "if not pdb_candidates:\n",
        "    raise FileNotFoundError(f\"No Boltz PDB outputs found under: {out_dir}\")\n",
        "model_pdb = sorted(pdb_candidates)[0]\n",
        "\n",
        "# copy\n",
        "complex_pdb = RUN_DIR / \"analysis\" / \"boltz_complex.pdb\"\n",
        "shutil.copyfile(model_pdb, complex_pdb)\n",
        "\n",
        "# --- locate affinity JSON ---\n",
        "aff_json = None\n",
        "json_candidates = list(out_dir.rglob(\"*.json\"))\n",
        "# prep aff files\n",
        "for p in sorted(json_candidates):\n",
        "    if \"affinity\" in p.name.lower():\n",
        "        aff_json = p\n",
        "        break\n",
        "if aff_json is None:\n",
        "    # look for keys containing affinity_pred_value fallback\n",
        "    for p in sorted(json_candidates):\n",
        "        try:\n",
        "            data = json.loads(p.read_text())\n",
        "            if any(\"affinity_pred_value\" in k for k in data.keys()):\n",
        "                aff_json = p\n",
        "                break\n",
        "        except Exception:\n",
        "            continue\n",
        "\n",
        "if aff_json is None:\n",
        "    boltz_log = RUN_DIR / \"logs\" / \"02_boltz.log\"\n",
        "    raise FileNotFoundError(\n",
        "        \"Affinity JSON not found in Boltz output. This notebook expects affinity outputs.\\n\"\n",
        "        f\"Check: {out_dir}\\n\"\n",
        "        f\"Tail of boltz log:\\n{tail(boltz_log, n=60)}\"\n",
        "    )\n",
        "\n",
        "# create a copy\n",
        "affinity_json_out = RUN_DIR / \"analysis\" / \"boltz_affinity.json\"\n",
        "shutil.copyfile(aff_json, affinity_json_out)\n",
        "\n",
        "# --- parse affinity_pred_value (Boltz reports log10(IC50 in µM)) ---\n",
        "data = json.loads(affinity_json_out.read_text())\n",
        "affinity_value = None\n",
        "affinity_prob = None\n",
        "\n",
        "for k, v in data.items():\n",
        "    if \"affinity_pred_value\" in k and isinstance(v, (int, float)):\n",
        "        affinity_value = float(v)\n",
        "        break\n",
        "for k, v in data.items():\n",
        "    if \"affinity_probability_binary\" in k and isinstance(v, (int, float)):\n",
        "        affinity_prob = float(v)\n",
        "        break\n",
        "\n",
        "if affinity_value is None:\n",
        "    raise RuntimeError(f\"Could not find affinity_pred_value in: {affinity_json_out.name}\")\n",
        "\n",
        "ic50_uM = 10**affinity_value\n",
        "R_kcal = 0.0019872041\n",
        "dG = R_kcal * float(TEMPERATURE_K) * math.log(ic50_uM * 1e-6)  # ΔG° = RT ln(Kd), Kd in M\n",
        "\n",
        "summary = {\n",
        "    \"run\": RUN_NAME,\n",
        "    \"complex_pdb\": str(complex_pdb),\n",
        "    \"affinity_log10_ic50_uM\": affinity_value,\n",
        "    \"ic50_uM\": ic50_uM,\n",
        "    \"ic50_nM\": ic50_uM * 1000.0,\n",
        "    \"deltaG_kcal_per_mol\": dG,\n",
        "    \"temperature_K\": float(TEMPERATURE_K),\n",
        "}\n",
        "if affinity_prob is not None:\n",
        "    summary[\"affinity_probability_binary\"] = affinity_prob\n",
        "\n",
        "# --- split protein + ligand from complex ---\n",
        "u = mda.Universe(str(complex_pdb))\n",
        "\n",
        "protein = u.select_atoms(\"protein\")\n",
        "if len(protein) == 0:\n",
        "    raise RuntimeError(\"Could not identify protein atoms in the Boltz PDB output.\")\n",
        "\n",
        "# Ligand: chainID L (from YAML) if present\n",
        "lig = u.select_atoms(\"chainID L and not protein and not nucleic and not resname HOH WAT\")\n",
        "if len(lig) == 0:\n",
        "    lig = u.select_atoms(\"not protein and not nucleic and not resname HOH WAT and not name NA CL K CA MG ZN\")\n",
        "\n",
        "receptor_pdb = RUN_DIR / \"analysis\" / \"receptor.pdb\"\n",
        "boltz_pose_pdb = RUN_DIR / \"analysis\" / \"boltz_ligand_pose.pdb\"\n",
        "\n",
        "protein.write(str(receptor_pdb))\n",
        "lig.write(str(boltz_pose_pdb))\n",
        "\n",
        "# convert lig to sdf\n",
        "extract_log = RUN_DIR / \"logs\" / \"03_extract.log\"\n",
        "boltz_pose_sdf = RUN_DIR / \"analysis\" / \"boltz_ligand_pose.sdf\"\n",
        "run_cmd(f\"obabel -ipdb {boltz_pose_pdb} -osdf -O {boltz_pose_sdf}\", extract_log)\n",
        "\n",
        "\n",
        "summary_path = RUN_DIR / \"analysis\" / \"boltz_summary.json\"\n",
        "summary_path.write_text(json.dumps(summary, indent=2))\n",
        "\n",
        "# key paths-\n",
        "state = {\n",
        "    \"complex_pdb\": str(complex_pdb),\n",
        "    \"receptor_pdb\": str(receptor_pdb),\n",
        "    \"boltz_pose_pdb\": str(boltz_pose_pdb),\n",
        "    \"boltz_pose_sdf\": str(boltz_pose_sdf),\n",
        "    \"affinity_json\": str(affinity_json_out),\n",
        "}\n",
        "(RUN_DIR / \"state\" / \"paths.json\").write_text(json.dumps(state, indent=2))\n",
        "\n",
        "print(\"Extracted:\")\n",
        "print(f\"  Complex PDB : {complex_pdb}\")\n",
        "print(f\"  Receptor PDB: {receptor_pdb}\")\n",
        "print(f\"  Boltz pose  : {boltz_pose_pdb}\")\n",
        "print(f\"  Boltz pose  : {boltz_pose_sdf}\")\n",
        "print(f\"  Affinity JSON: {affinity_json_out}\")\n",
        "\n",
        "print(f\"\\nAffinity (Boltz): log10(IC50 µM) = {affinity_value:.3f}\")\n",
        "print(f\"  IC50 ~ {ic50_uM:.3g} µM  ({ic50_uM*1000:.3g} nM)\")\n",
        "print(f\"  ΔG°({TEMPERATURE_K} K) ~ {dG:.2f} kcal/mol  (approx.)\")\n",
        "if affinity_prob is not None:\n",
        "    print(f\"  P(binder) ~ {affinity_prob:.3f}\")\n",
        "\n",
        "print(f\"\\nLogs: {extract_log}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51a4d210",
      "metadata": {
        "cellView": "form",
        "id": "51a4d210"
      },
      "outputs": [],
      "source": [
        "#@title **D3) Visualize Boltz complex (py3Dmol)**\n",
        "\n",
        "import py3Dmol\n",
        "from pathlib import Path\n",
        "\n",
        "receptor_pdb = RUN_DIR / \"analysis\" / \"receptor.pdb\"\n",
        "boltz_pose_sdf = RUN_DIR / \"analysis\" / \"boltz_ligand_pose.sdf\"\n",
        "\n",
        "\n",
        "PINE_GREEN = \"#01796f\"  # Boltz pose color\n",
        "\n",
        "view = py3Dmol.view(width=900, height=520)\n",
        "view.setViewStyle({'style':'outline','color':'black','width':0.05})\n",
        "\n",
        "# receptor viz\n",
        "view.addModel(open(receptor_pdb).read(), \"pdb\")\n",
        "view.setStyle({\"cartoon\": {\"color\": \"white\"}})\n",
        "\n",
        "# surface viz\n",
        "view.addSurface(py3Dmol.VDW, {'opacity': 0.6, 'color': 'silver'})\n",
        "\n",
        "# ligand viz\n",
        "view.addModel(open(boltz_pose_sdf).read(), \"sdf\")\n",
        "view.setStyle({\"model\": 1}, {\"stick\": {\"color\": PINE_GREEN, \"radius\": 0.25}})\n",
        "\n",
        "view.zoomTo()\n",
        "view.show()\n",
        "\n",
        "print(\"Boltz complex preview (protein + predicted ligand pose).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2MczgnP746Wr",
      "metadata": {
        "id": "2MczgnP746Wr"
      },
      "source": [
        "## **E. P2Rank: pocket hypotheses**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FaqX7w0X46Wr",
      "metadata": {
        "cellView": "form",
        "id": "FaqX7w0X46Wr"
      },
      "outputs": [],
      "source": [
        "#@title **E1) Run P2Rank + show top pockets**\n",
        "\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "\n",
        "receptor_pdb = RUN_DIR / \"analysis\" / \"receptor.pdb\"\n",
        "p2rank_out = RUN_DIR / \"p2rank\"\n",
        "p2rank_log = RUN_DIR / \"logs\" / \"04_p2rank.log\"\n",
        "\n",
        "# --- call P2Rank ---\n",
        "p2rank_version_dir = TOOLS_DIR / f\"p2rank_{P2RANK_VERSION}\"\n",
        "if not p2rank_version_dir.exists():\n",
        "    raise FileNotFoundError(f\"P2Rank installation directory not found: {p2rank_version_dir}. Re-run B1.\")\n",
        "\n",
        "prank_executable_path = p2rank_version_dir / \"prank\"\n",
        "if not prank_executable_path.exists():\n",
        "    raise FileNotFoundError(f\"P2Rank 'prank' executable not found at: {prank_executable_path}. Re-run B1.\")\n",
        "\n",
        "run_cmd(f\"{prank_executable_path} predict -f {receptor_pdb} -o {p2rank_out} -c alphafold\", p2rank_log, cwd=p2rank_version_dir)\n",
        "\n",
        "csv_candidates = list(p2rank_out.rglob(\"*_predictions.csv\"))\n",
        "if not csv_candidates:\n",
        "    raise FileNotFoundError(f\"No *_predictions.csv found under: {p2rank_out}\\nCheck logs at: {p2rank_log}\")\n",
        "pred_csv = sorted(csv_candidates)[0]\n",
        "\n",
        "df = pd.read_csv(pred_csv)\n",
        "\n",
        "def pick_col(substrs):\n",
        "    for s in substrs:\n",
        "        for c in df.columns:\n",
        "            if s in c.lower():\n",
        "                return c\n",
        "    return None\n",
        "\n",
        "col_score = pick_col([\"score\", \"probability\", \"pocket_score\"])\n",
        "col_res   = pick_col([\"residue\", \"residues\"])\n",
        "col_cx    = pick_col([\"center_x\", \"centerx\", \"center x\"])\n",
        "col_cy    = pick_col([\"center_y\", \"centery\", \"center y\"])\n",
        "col_cz    = pick_col([\"center_z\", \"centerz\", \"center z\"])\n",
        "\n",
        "df_disp = df.copy()\n",
        "df_disp.insert(0, \"pocket_rank\", range(1, len(df_disp)+1))\n",
        "\n",
        "keep_cols = [\"pocket_rank\"]\n",
        "for c in [col_score, col_cx, col_cy, col_cz, col_res]:\n",
        "    if c and c not in keep_cols:\n",
        "        keep_cols.append(c)\n",
        "\n",
        "p2rank_csv_out = RUN_DIR / \"analysis\" / \"p2rank_pockets.csv\"\n",
        "df_disp[keep_cols].to_csv(p2rank_csv_out, index=False)\n",
        "\n",
        "print(\"Top pockets (P2Rank):\")\n",
        "show_table(df_disp[keep_cols], max_rows=5)\n",
        "print(f\"\\nSaved: {p2rank_csv_out}\")\n",
        "print(f\"P2Rank log: {p2rank_log}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0437fc3",
      "metadata": {
        "cellView": "form",
        "id": "a0437fc3"
      },
      "outputs": [],
      "source": [
        "#@title **E2) Select pocket for GNINA (and visualize)**\n",
        "#@markdown Select a pocket from the P2Rank table or manual selection.\n",
        "\n",
        "POCKET_MODE = \"choose_rank\"  #@param [\"auto_top1\",\"choose_rank\",\"manual_residues\"]\n",
        "POCKET_RANK = 1  #@param {type:\"integer\"}\n",
        "#@markdown Manual residues examples: `A:123, A:125-130` or `A:45-60`\n",
        "\n",
        "POCKET_RESIDUES = \"\"  #@param {type:\"string\"}\n",
        "\n",
        "import pandas as pd\n",
        "import json\n",
        "import re\n",
        "import MDAnalysis as mda\n",
        "import py3Dmol\n",
        "from pathlib import Path\n",
        "\n",
        "receptor_pdb = RUN_DIR / \"analysis\" / \"receptor.pdb\"\n",
        "boltz_pose_sdf = RUN_DIR / \"analysis\" / \"boltz_ligand_pose.sdf\"\n",
        "pockets_csv = RUN_DIR / \"analysis\" / \"p2rank_pockets.csv\"\n",
        "\n",
        "if not pockets_csv.exists():\n",
        "    raise FileNotFoundError(\"Missing p2rank_pockets.csv. Run E1 first.\")\n",
        "\n",
        "df = pd.read_csv(pockets_csv)\n",
        "\n",
        "# residue-list column\n",
        "res_col = None\n",
        "for c in df.columns:\n",
        "    if \"res\" in c.lower():\n",
        "        res_col = c\n",
        "        break\n",
        "\n",
        "def parse_residue_spec(spec: str):\n",
        "    \"\"\"Parse strings like 'A:123, A:125-130'. Returns list of (chain, resid).\"\"\"\n",
        "    out=[]\n",
        "    spec = spec.replace(\" \", \"\")\n",
        "    if not spec:\n",
        "        return out\n",
        "    parts = [p for p in spec.split(\",\") if p]\n",
        "    for p in parts:\n",
        "        if \":\" not in p:\n",
        "            raise ValueError(f\"Residue '{p}' must include a chain, e.g. A:123\")\n",
        "        chain, rng = p.split(\":\", 1)\n",
        "        if \"-\" in rng:\n",
        "            a,b = rng.split(\"-\",1)\n",
        "            for r in range(int(a), int(b)+1):\n",
        "                out.append((chain, r))\n",
        "        else:\n",
        "            out.append((chain, int(rng)))\n",
        "    return out\n",
        "\n",
        "# residue select\n",
        "if POCKET_MODE == \"auto_top1\":\n",
        "    pocket_rank = 1\n",
        "elif POCKET_MODE == \"choose_rank\":\n",
        "    pocket_rank = int(POCKET_RANK)\n",
        "else:\n",
        "    pocket_rank = None  # manual\n",
        "\n",
        "if pocket_rank is not None:\n",
        "    if pocket_rank < 1 or pocket_rank > len(df):\n",
        "        raise ValueError(f\"Pocket rank {pocket_rank} is out of range (1..{len(df)}).\")\n",
        "    residues_blob = str(df.loc[pocket_rank-1, res_col]) if res_col else \"\"\n",
        "    tokens = re.split(r\"[,\\s]+\", residues_blob.strip())\n",
        "    residues=[]\n",
        "    for t in tokens:\n",
        "        if not t:\n",
        "            continue\n",
        "        if \":\" in t:\n",
        "            ch, r = t.split(\":\", 1)\n",
        "        elif \"_\" in t:\n",
        "            ch, r = t.split(\"_\", 1)\n",
        "        else:\n",
        "            continue\n",
        "        try:\n",
        "            residues.append((ch, int(re.sub(r\"\\D\",\"\", r))))\n",
        "        except ValueError:\n",
        "            pass\n",
        "else:\n",
        "    residues = parse_residue_spec(POCKET_RESIDUES)\n",
        "\n",
        "if not residues:\n",
        "    raise RuntimeError(\"No pocket residues found/selected. Try another pocket rank or manual residues.\")\n",
        "\n",
        "# pocket build\n",
        "u = mda.Universe(str(receptor_pdb))\n",
        "sel_parts = [f\"(chainID {ch} and resid {rid})\" for ch,rid in residues]\n",
        "sel = \" or \".join(sel_parts)\n",
        "pocket_atoms = u.select_atoms(sel)\n",
        "\n",
        "pocket_pdb = RUN_DIR / \"analysis\" / \"pocket_residues.pdb\"\n",
        "pocket_atoms.write(str(pocket_pdb))\n",
        "\n",
        "sel_state = {\n",
        "    \"pocket_mode\": POCKET_MODE,\n",
        "    \"pocket_rank\": pocket_rank,\n",
        "    \"n_residues\": len(residues),\n",
        "    \"pocket_pdb\": str(pocket_pdb),\n",
        "}\n",
        "(RUN_DIR / \"state\" / \"pocket.json\").write_text(json.dumps(sel_state, indent=2))\n",
        "\n",
        "print(f\"Selected pocket residues: {len(residues)} residues\")\n",
        "print(f\"Pocket residue PDB: {pocket_pdb}\")\n",
        "\n",
        "# --- viz (protein + Boltz pose + selected pocket residues) ---\n",
        "PINE_GREEN = \"#01796f\"  # Boltz pose\n",
        "ROSE_RED = \"#ff033e\"    # GNINA poses (used later)\n",
        "\n",
        "view = py3Dmol.view(width=900, height=520)\n",
        "view.setViewStyle({'style':'outline','color':'black','width':0.05})\n",
        "\n",
        "view.addModel(open(receptor_pdb).read(), \"pdb\")\n",
        "view.setStyle({\"cartoon\": {\"color\": \"#fffafa\"}})\n",
        "\n",
        "view.addModel(open(pocket_pdb).read(), \"pdb\")\n",
        "view.setStyle({\"model\": 1}, {\"stick\": {\"color\": \"#cc9900\", \"radius\": 0.25}})\n",
        "\n",
        "view.addModel(open(boltz_pose_sdf).read(), \"sdf\")\n",
        "view.setStyle({\"model\": 2}, {\"stick\": {\"color\": PINE_GREEN, \"radius\": 0.28}})\n",
        "\n",
        "view.zoomTo()\n",
        "view.show()\n",
        "\n",
        "print(\"Pocket preview: yellow = selected pocket residues, green = Boltz ligand pose.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QTZsJF6F46Wr",
      "metadata": {
        "id": "QTZsJF6F46Wr"
      },
      "source": [
        "## **F. GNINA: re-dock + re-score**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vZFyZ_9g46Wr",
      "metadata": {
        "cellView": "form",
        "id": "vZFyZ_9g46Wr"
      },
      "outputs": [],
      "source": [
        "#@title **F1) Run GNINA docking + re-score the Boltz pose**\n",
        "#@markdown Dock into the **selected pocket** (E2), then **re-score** the original Boltz pose once for comparison.\n",
        "\n",
        "#@markdown **Feel free to adjust the parameters below.**\n",
        "GNINA_POSES = 10  #@param {type:\"integer\"}\n",
        "GNINA_EXHAUSTIVENESS = 8  #@param {type:\"integer\"}\n",
        "AUTOBOX_ADD = 4.0  #@param {type:\"number\"}\n",
        "PH = 7.4  #@param {type:\"number\"}\n",
        "\n",
        "import json\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import re\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "try:\n",
        "    from IPython.display import display\n",
        "except ImportError:\n",
        "    pass\n",
        "\n",
        "# logging\n",
        "gnina_log = RUN_DIR / \"logs\" / \"05_gnina.log\"\n",
        "gnina_score_log = RUN_DIR / \"logs\" / \"05_gnina_score_only.log\"\n",
        "ligprep_log = RUN_DIR / \"logs\" / \"05_ligprep.log\"\n",
        "\n",
        "receptor_pdb = RUN_DIR / \"analysis\" / \"receptor.pdb\"\n",
        "boltz_pose_sdf = RUN_DIR / \"analysis\" / \"boltz_ligand_pose.sdf\"\n",
        "\n",
        "if \"pocket_pdb\" not in globals():\n",
        "    raise RuntimeError(\"Missing pocket selection. Run E2 first.\")\n",
        "pocket_pdb = Path(pocket_pdb)\n",
        "\n",
        "# ------------------------------------------------------------------------\n",
        "# troubleshooting -PREPARE RECEPTOR (Protonate + Fix UNK Labels)\n",
        "# ------------------------------------------------------------------------\n",
        "receptor_dock_pdb = RUN_DIR / \"gnina\" / \"receptor_ph.pdb\"\n",
        "receptor_dock_pdb.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"Protonating receptor at pH {PH}...\")\n",
        "run_cmd(f\"obabel -ipdb {receptor_pdb} -opdb -O {receptor_dock_pdb} -p {PH}\", ligprep_log)\n",
        "\n",
        "# PATCH with bipoython\n",
        "try:\n",
        "    from Bio import PDB\n",
        "    #print(\"Running residue name patch (fixing 'UNK' labels)...\")\n",
        "    parser = PDB.PDBParser(QUIET=True)\n",
        "    ref_structure = parser.get_structure(\"ref\", str(receptor_pdb))\n",
        "    tgt_structure = parser.get_structure(\"tgt\", str(receptor_dock_pdb))\n",
        "\n",
        "    res_name_map = {}\n",
        "    for model in ref_structure:\n",
        "        for chain in model:\n",
        "            for residue in chain:\n",
        "                key = (chain.id, residue.id[1], residue.id[2])\n",
        "                res_name_map[key] = residue.resname\n",
        "\n",
        "    count_fixed = 0\n",
        "    for model in tgt_structure:\n",
        "        for chain in model:\n",
        "            for residue in chain:\n",
        "                key = (chain.id, residue.id[1], residue.id[2])\n",
        "                if key in res_name_map:\n",
        "                    original_name = res_name_map[key]\n",
        "                    if residue.resname == \"UNK\" or residue.resname != original_name:\n",
        "                        residue.resname = original_name\n",
        "                        count_fixed += 1\n",
        "\n",
        "    receptor_dock_pdb_fixed = RUN_DIR / \"gnina\" / \"receptor_ph_fixed.pdb\"\n",
        "    io = PDB.PDBIO()\n",
        "    io.set_structure(tgt_structure)\n",
        "    io.save(str(receptor_dock_pdb_fixed))\n",
        "    receptor_dock_pdb = receptor_dock_pdb_fixed\n",
        "    #print(f\"   Patch applied. Restored {count_fixed} residue names.\")\n",
        "\n",
        "except ImportError:\n",
        "    print(\"   BioPython not installed. Skipping 'UNK' patch.\")\n",
        "except Exception as e:\n",
        "    print(f\"   Patch failed: {e}. Proceeding with unpatched file.\")\n",
        "\n",
        "# ------------------------------------------------------------------------\n",
        "# PREPARE LIGAND\n",
        "# ------------------------------------------------------------------------\n",
        "lig_in_sdf = RUN_DIR / \"gnina\" / \"ligand_mmff.sdf\"\n",
        "smiles = LIGAND_SMILES.strip()\n",
        "ph_smiles = smiles\n",
        "\n",
        "try:\n",
        "    from dimorphite_dl import protonate_smiles\n",
        "    prot_list = protonate_smiles(smiles, ph_min=PH-0.5, ph_max=PH+0.5)\n",
        "    if prot_list: ph_smiles = prot_list[0]\n",
        "except:\n",
        "    pass\n",
        "\n",
        "mol = Chem.MolFromSmiles(ph_smiles)\n",
        "if mol:\n",
        "    mol = Chem.AddHs(mol)\n",
        "    AllChem.EmbedMolecule(mol, AllChem.ETKDGv3())\n",
        "    try: AllChem.MMFFOptimizeMolecule(mol, mmffVariant=\"MMFF94s\")\n",
        "    except: AllChem.UFFOptimizeMolecule(mol)\n",
        "    with Chem.SDWriter(str(lig_in_sdf)) as w:\n",
        "        w.write(mol)\n",
        "else:\n",
        "    raise ValueError(\"Failed to process ligand SMILES.\")\n",
        "\n",
        "# ------------------------------------------------------------------------\n",
        "# RUN GNINA (Docking)\n",
        "# ------------------------------------------------------------------------\n",
        "dock_sdf = RUN_DIR / \"gnina\" / \"gnina_docked.sdf\"\n",
        "summary_csv = RUN_DIR / \"analysis\" / \"gnina_pose_summary.csv\"\n",
        "\n",
        "print(\"Running GNINA docking...\")\n",
        "gnina_cmd = (\n",
        "    f\"gnina --receptor {receptor_dock_pdb} --ligand {lig_in_sdf} \"\n",
        "    f\"--autobox_ligand {pocket_pdb} --autobox_add {AUTOBOX_ADD} \"\n",
        "    f\"--num_modes {GNINA_POSES} --exhaustiveness {GNINA_EXHAUSTIVENESS} \"\n",
        "    f\"--out {dock_sdf}\"\n",
        ")\n",
        "run_cmd(gnina_cmd, gnina_log)\n",
        "\n",
        "# ------------------------------------------------------------------------\n",
        "# SCORE BOLTZ POSE (Score Only)\n",
        "# ------------------------------------------------------------------------\n",
        "boltz_pose_ph_sdf = RUN_DIR / \"analysis\" / \"boltz_ligand_pose_ph.sdf\"\n",
        "run_cmd(f\"obabel -isdf {boltz_pose_sdf} -osdf -O {boltz_pose_ph_sdf} -p {PH}\", ligprep_log)\n",
        "\n",
        "print(\"Scoring Boltz pose...\")\n",
        "run_cmd(f\"gnina --score_only --receptor {receptor_dock_pdb} --ligand {boltz_pose_ph_sdf}\", gnina_score_log)\n",
        "\n",
        "# ------------------------------------------------------------------------\n",
        "# PARSE RESULTS (troubleshooting)\n",
        "# ------------------------------------------------------------------------\n",
        "def _prop(m, key):\n",
        "    return float(m.GetProp(key)) if m and m.HasProp(key) else float('nan')\n",
        "\n",
        "rows = []\n",
        "sup = Chem.SDMolSupplier(str(dock_sdf), removeHs=False)\n",
        "for i, m in enumerate(sup):\n",
        "    if m:\n",
        "        rows.append({\n",
        "            \"pose_id\": i+1,\n",
        "            \"CNNscore\": _prop(m, \"CNNscore\"),\n",
        "            \"CNNaffinity\": _prop(m, \"CNNaffinity\"),\n",
        "            \"minimizedAffinity\": _prop(m, \"minimizedAffinity\")\n",
        "        })\n",
        "df_dock = pd.DataFrame(rows)\n",
        "df_dock.to_csv(summary_csv, index=False)\n",
        "\n",
        "txt = Path(gnina_score_log).read_text(errors=\"ignore\")\n",
        "def get_score(name):\n",
        "    # Matches 'Name: 123' or 'Name 123'\n",
        "    m = re.findall(rf\"{name}[:\\s]+([-+]?[0-9]*\\.?[0-9]+)\", txt)\n",
        "    return float(m[-1]) if m else float('nan')\n",
        "\n",
        "# fallback for vina affinity\n",
        "vina_score = get_score(\"minimizedAffinity\")\n",
        "if pd.isna(vina_score):\n",
        "    vina_score = get_score(\"Affinity\")\n",
        "\n",
        "boltz_scores = {\n",
        "    \"CNNscore\": get_score(\"CNNscore\"),\n",
        "    \"CNNaffinity\": get_score(\"CNNaffinity\"),\n",
        "    \"minimizedAffinity\": vina_score\n",
        "}\n",
        "(RUN_DIR / \"analysis\" / \"boltz_pose_gnina_scores.json\").write_text(json.dumps(boltz_scores, indent=2))\n",
        "\n",
        "paths = RUN_DIR / \"state\" / \"paths.json\"\n",
        "if paths.exists():\n",
        "    d = json.loads(paths.read_text())\n",
        "    d.update({\n",
        "        \"receptor_pdb_ph\": str(receptor_dock_pdb),\n",
        "        \"boltz_pose_sdf_ph\": str(boltz_pose_ph_sdf)\n",
        "    })\n",
        "    paths.write_text(json.dumps(d, indent=2))\n",
        "\n",
        "print(f\"\\n   Done. Summary: {summary_csv}\")\n",
        "print(f\"   Boltz Scores (Raw): {boltz_scores}\")\n",
        "\n",
        "print(\"\\n--- Top 3 GNINA Poses ---\")\n",
        "if not df_dock.empty:\n",
        "    display(df_dock.sort_values(\"CNNaffinity\", ascending=False).head(3))\n",
        "else:\n",
        "    print(\"No docked poses found.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a03db1fa",
      "metadata": {
        "cellView": "form",
        "id": "a03db1fa"
      },
      "outputs": [],
      "source": [
        "#@title **F2) Plot GNINA scores**\n",
        "#@markdown Plot a metric from the saved GNINA summary and overlay the Boltz score.\n",
        "\n",
        "PLOT_METRIC = \"minimizedAffinity\"  #@param [\"CNNscore\",\"CNNaffinity\",\"minimizedAffinity\"]\n",
        "TOP_N = 10  #@param {type:\"integer\"}\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import numpy as np\n",
        "import re\n",
        "from pathlib import Path\n",
        "\n",
        "summary_csv = RUN_DIR / \"analysis\" / \"gnina_pose_summary.csv\"\n",
        "boltz_scores_json = RUN_DIR / \"analysis\" / \"boltz_pose_gnina_scores.json\"\n",
        "plot_png = RUN_DIR / \"analysis\" / f\"gnina_{PLOT_METRIC}_plot.png\"\n",
        "\n",
        "df = pd.read_csv(summary_csv)\n",
        "boltz_scores = json.loads(Path(boltz_scores_json).read_text())\n",
        "\n",
        "# --- NaN fix ---\n",
        "gnina_score_log = RUN_DIR / \"logs\" / \"05_gnina_score_only.log\"\n",
        "if any(pd.isna(v) for v in boltz_scores.values()) and gnina_score_log.exists():\n",
        "    txt = gnina_score_log.read_text(errors=\"ignore\")\n",
        "    def find_val(name):\n",
        "        # Matches \"Name 1.23\" OR \"Name: 1.23\"\n",
        "        m = re.findall(rf\"{name}[:\\s]+([-0-9.]+)\", txt)\n",
        "        return float(m[-1]) if m else float(\"nan\")\n",
        "\n",
        "    # update scores\n",
        "    s = find_val(\"CNNscore\")\n",
        "    if s == s: boltz_scores[\"CNNscore\"] = s\n",
        "\n",
        "    s = find_val(\"CNNaffinity\")\n",
        "    if s == s: boltz_scores[\"CNNaffinity\"] = s\n",
        "\n",
        "    s = find_val(\"minimizedAffinity\")\n",
        "    if s != s: s = find_val(\"Affinity\")\n",
        "    if s == s: boltz_scores[\"minimizedAffinity\"] = s\n",
        "\n",
        "    print(f\"Recovered Boltz scores: {boltz_scores}\")\n",
        "\n",
        "ascending = (PLOT_METRIC == \"minimizedAffinity\")\n",
        "dff = df.sort_values(PLOT_METRIC, ascending=ascending).head(TOP_N).copy()\n",
        "\n",
        "x = np.arange(len(dff))\n",
        "y = dff[PLOT_METRIC].astype(float).values\n",
        "\n",
        "# --- viz ---\n",
        "plt.rcParams['font.family'] = 'sans-serif'\n",
        "plt.rcParams['font.weight'] = 'semibold'\n",
        "plt.rcParams['axes.labelweight'] = 'semibold'\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8.0, 4.0))\n",
        "\n",
        "ax.plot(x, y, marker='o', linestyle='None',\n",
        "        color='#367588', markersize=8, label='GNINA poses')\n",
        "\n",
        "b = boltz_scores.get(PLOT_METRIC, float(\"nan\"))\n",
        "if b == b:  # not NaN\n",
        "    # grey (#808080)\n",
        "    ax.axhline(b, linestyle=\"--\", linewidth=1, color=\"#808080\", label=f\"Boltz\")\n",
        "else:\n",
        "    print(f\"(Note: Boltz baseline for {PLOT_METRIC} is NaN, so dashed line is hidden)\")\n",
        "\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(dff[\"pose_id\"].astype(int).values)\n",
        "\n",
        "ax.set_xlabel(\"Pose ID\")\n",
        "\n",
        "if PLOT_METRIC == \"minimizedAffinity\":\n",
        "    ax.set_ylabel(\"minimizedAffinity (kcal/mol)\")\n",
        "elif PLOT_METRIC == \"CNNaffinity\":\n",
        "    ax.set_ylabel(\"CNNaffinity\")\n",
        "else:\n",
        "    ax.set_ylabel(\"CNNscore\")\n",
        "\n",
        "# spines\n",
        "ax.spines['top'].set_visible(False)\n",
        "ax.spines['right'].set_visible(False)\n",
        "\n",
        "# legend\n",
        "ax.legend(bbox_to_anchor=(1.02, 0.9), loc='upper left', frameon=False)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(plot_png, dpi=400)\n",
        "plt.show()\n",
        "\n",
        "print(f\"Saved plot: {plot_png}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Ni-RGZOv46Ws",
      "metadata": {
        "id": "Ni-RGZOv46Ws"
      },
      "source": [
        "## **G. Quick visual comparison**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RAsP8kMK46Ws",
      "metadata": {
        "cellView": "form",
        "id": "RAsP8kMK46Ws"
      },
      "outputs": [],
      "source": [
        "#@title **G1) Compare Boltz vs GNINA poses (animated)**\n",
        "#@markdown Animate GNINA poses (red) over the Boltz pose (green).\n",
        "\n",
        "MAX_MODES = 10  #@param {type:\"integer\"}\n",
        "INTERVAL_MS = 600  #@param {type:\"integer\"}\n",
        "\n",
        "from pathlib import Path\n",
        "from rdkit import Chem\n",
        "import py3Dmol\n",
        "\n",
        "receptor_pdb   = RUN_DIR / \"analysis\" / \"receptor.pdb\"\n",
        "pocket_pdb     = RUN_DIR / \"analysis\" / \"pocket_residues.pdb\"\n",
        "boltz_pose_sdf = RUN_DIR / \"analysis\" / \"boltz_ligand_pose.sdf\"\n",
        "docked_sdf     = RUN_DIR / \"gnina\" / \"gnina_docked.sdf\"\n",
        "\n",
        "PINE_GREEN = \"#01796f\"\n",
        "ROSE_RED   = \"#ff033e\"\n",
        "\n",
        "# frame limit\n",
        "poses = [m for m in Chem.SDMolSupplier(str(docked_sdf), removeHs=False) if m is not None]\n",
        "if not poses:\n",
        "    raise RuntimeError(\"No GNINA poses found. Run F1 first.\")\n",
        "\n",
        "n = max(1, min(int(MAX_MODES), len(poses)))\n",
        "tmp_sdf = RUN_DIR / \"analysis\" / f\"gnina_first_{n}_poses.sdf\"\n",
        "w = Chem.SDWriter(str(tmp_sdf))\n",
        "for m in poses[:n]:\n",
        "    w.write(m)\n",
        "w.close()\n",
        "\n",
        "view = py3Dmol.view(width=900, height=520)\n",
        "view.setViewStyle({'style':'outline','color':'black','width':0.05})\n",
        "\n",
        "# --- receptor viz ---\n",
        "view.addModel(open(receptor_pdb).read(), \"pdb\")\n",
        "view.setStyle({'model': 0}, {\"cartoon\": {\"color\": \"white\"}})\n",
        "\n",
        "# --- surface viz ---\n",
        "view.addSurface(py3Dmol.VDW, {'opacity': 0.6, 'color': 'silver'}, {'model': 0})\n",
        "\n",
        "current_idx = 0\n",
        "\n",
        "# --- pocket optional ---\n",
        "if pocket_pdb.exists():\n",
        "    view.addModel(open(pocket_pdb).read(), \"pdb\")\n",
        "    current_idx += 1\n",
        "    view.setStyle({'model': current_idx}, {\"stick\": {\"color\": \"grey\", \"radius\": 0.25}})\n",
        "\n",
        "# --- boltz pose viz ---\n",
        "view.addModel(open(boltz_pose_sdf).read(), \"sdf\")\n",
        "current_idx += 1\n",
        "view.setStyle({'model': current_idx}, {\"stick\": {\"color\": PINE_GREEN, \"radius\": 0.28}})\n",
        "\n",
        "# --- gnina poses viz ---\n",
        "gnina_data = open(tmp_sdf).read()\n",
        "view.addModelsAsFrames(gnina_data, \"sdf\")\n",
        "current_idx += 1\n",
        "\n",
        "view.setStyle({'model': current_idx}, {\"stick\": {\"color\": ROSE_RED, \"radius\": 0.22}})\n",
        "\n",
        "view.zoomTo()\n",
        "view.animate({'loop': 'forward', 'interval': int(INTERVAL_MS)})\n",
        "view.show()\n",
        "\n",
        "print(f\"Animating {n} GNINA poses (rose red) over Boltz pose (pine green).\")\n",
        "print(f\"Frames source: {tmp_sdf}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KJ-3fRm846Ws",
      "metadata": {
        "id": "KJ-3fRm846Ws"
      },
      "source": [
        "## **H. QC + interactions**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KpEVOyug46Ws",
      "metadata": {
        "cellView": "form",
        "id": "KpEVOyug46Ws"
      },
      "outputs": [],
      "source": [
        "#@title **H1) Run PoseBusters and ProLIF for QC and interaction comparison**\n",
        "\n",
        "POSE_SELECTION = \"minimizedAffinity\"  #@param [\"Manual\", \"CNNscore\",\"CNNaffinity\",\"minimizedAffinity\"]\n",
        "MANUAL_POSE_ID = 1  #@param {type:\"integer\"}\n",
        "CONTACT_CUTOFF_A = 6.0\n",
        "\n",
        "import sys\n",
        "import json\n",
        "import datetime, html, subprocess, shutil\n",
        "from pathlib import Path\n",
        "from IPython.display import display, HTML\n",
        "import MDAnalysis as mda\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# --- setup & checks ---\n",
        "chem_path = RUN_DIR / \"state\" / \"chem.json\"\n",
        "PH = float(json.loads(chem_path.read_text()).get(\"pH\", 7.4)) if chem_path.exists() else 7.4\n",
        "ts = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "receptor_pdb = RUN_DIR / \"analysis\" / \"receptor.pdb\"\n",
        "boltz_pose_sdf = RUN_DIR / \"analysis\" / \"boltz_ligand_pose.sdf\"\n",
        "dock_sdf = RUN_DIR / \"gnina\" / \"gnina_docked.sdf\"\n",
        "summary_csv = RUN_DIR / \"analysis\" / \"gnina_pose_summary.csv\"\n",
        "\n",
        "if not summary_csv.exists():\n",
        "    raise RuntimeError(\"Missing GNINA summary. Run F1 first.\")\n",
        "\n",
        "df_summary = pd.read_csv(summary_csv)\n",
        "if len(df_summary) == 0:\n",
        "    raise RuntimeError(\"No GNINA poses found.\")\n",
        "\n",
        "# pose selection\n",
        "if POSE_SELECTION == \"Manual\":\n",
        "    pose_id = int(MANUAL_POSE_ID)\n",
        "    print(f\"Selected pose_id: {pose_id} (Manual)\")\n",
        "else:\n",
        "    ascending = (POSE_SELECTION == \"minimizedAffinity\")\n",
        "    pose_id = int(df_summary.sort_values(POSE_SELECTION, ascending=ascending).iloc[0][\"pose_id\"])\n",
        "    print(f\"Selected pose_id: {pose_id} (Best by {POSE_SELECTION})\")\n",
        "\n",
        "best_pose_sdf = RUN_DIR / \"analysis\" / f\"gnina_best_pose_{pose_id}.sdf\"\n",
        "\n",
        "# pose extraction fxn\n",
        "from rdkit import Chem\n",
        "sup = Chem.SDMolSupplier(str(dock_sdf), removeHs=False)\n",
        "m = sup[pose_id-1]\n",
        "w = Chem.SDWriter(str(best_pose_sdf))\n",
        "w.write(m); w.close()\n",
        "\n",
        "# --- try posebusters CLI ---\n",
        "print(\"\\nRunning PoseBusters...\")\n",
        "for name, sdf_path in [(\"Boltz\", boltz_pose_sdf), (\"GNINA\", best_pose_sdf)]:\n",
        "    csv_out = RUN_DIR / \"analysis\" / f\"posebusters_{name.lower()}_{ts}.csv\"\n",
        "    cmd = [sys.executable, \"-m\", \"posebusters\", str(sdf_path), \"-p\", str(receptor_pdb), \"--outfmt\", \"csv\", \"--full-report\"]\n",
        "    try:\n",
        "        p = subprocess.run(cmd, capture_output=True, text=True)\n",
        "        csv_out.write_text(p.stdout)\n",
        "        if p.returncode == 0 and len(p.stdout.strip()) > 0:\n",
        "            print(f\"  {name} Report saved.\")\n",
        "        else:\n",
        "            print(f\"  WARNING: {name} PoseBusters failed (empty output).\")\n",
        "    except Exception as e:\n",
        "        print(f\"  Error running PoseBusters for {name}: {e}\")\n",
        "\n",
        "# --- ensure right protonation ---\n",
        "print(f\"\\nChecking protonation at (pH {PH})...\")\n",
        "receptor_h_pdb = RUN_DIR / \"analysis\" / \"receptor_prolif_H.pdb\"\n",
        "boltz_h_sdf = RUN_DIR / \"analysis\" / \"boltz_pose_prolif_H.sdf\"\n",
        "gnina_h_sdf = RUN_DIR / \"analysis\" / f\"gnina_pose_{pose_id}_prolif_H.sdf\"\n",
        "hlog = RUN_DIR / \"logs\" / \"07_hydrogens.log\"\n",
        "\n",
        "def run_obabel_h(inp, outp, ph):\n",
        "    run_cmd(f\"obabel {inp} -O {outp} -p {ph}\", hlog)\n",
        "\n",
        "run_obabel_h(receptor_pdb, receptor_h_pdb, PH)\n",
        "\n",
        "# check for UNK resname\n",
        "try:\n",
        "    from Bio import PDB\n",
        "    parser = PDB.PDBParser(QUIET=True)\n",
        "    ref_st = parser.get_structure(\"ref\", str(receptor_pdb))\n",
        "    tgt_st = parser.get_structure(\"tgt\", str(receptor_h_pdb))\n",
        "\n",
        "    mapping = {(c.id, r.id[1], r.id[2]): r.resname for m in ref_st for c in m for r in c}\n",
        "    fallback = {(r.id[1], r.id[2]): r.resname for m in ref_st for c in m for r in c}\n",
        "\n",
        "    fixed = 0\n",
        "    for m in tgt_st:\n",
        "        for c in m:\n",
        "            for r in c:\n",
        "                val = mapping.get((c.id, r.id[1], r.id[2])) or fallback.get((r.id[1], r.id[2]))\n",
        "                if val and r.resname != val:\n",
        "                    r.resname = val\n",
        "                    fixed += 1\n",
        "    if fixed > 0:\n",
        "        io = PDB.PDBIO()\n",
        "        io.set_structure(tgt_st)\n",
        "        io.save(str(receptor_h_pdb))\n",
        "        #print(f\"  [Patch] Restored {fixed} residue names.\")\n",
        "except Exception as e:\n",
        "    #print(f\"  [Patch] Warning: {e}\")\n",
        "    pass\n",
        "\n",
        "run_obabel_h(boltz_pose_sdf, boltz_h_sdf, PH)\n",
        "run_obabel_h(best_pose_sdf, gnina_h_sdf, PH)\n",
        "\n",
        "# --- ProLIF fxns ---\n",
        "print(\"\\nRunning ProLIF (Interactions)...\")\n",
        "try:\n",
        "    import prolif as plf\n",
        "    from prolif.interactions import VdWContact\n",
        "\n",
        "    # try loading\n",
        "    prot_mol = Chem.MolFromPDBFile(str(receptor_h_pdb), removeHs=False, sanitize=False)\n",
        "    Chem.SanitizeMol(prot_mol, Chem.SanitizeFlags.SANITIZE_ALL ^ Chem.SanitizeFlags.SANITIZE_PROPERTIES)\n",
        "    prot = plf.Molecule.from_rdkit(prot_mol)\n",
        "\n",
        "    # fingerprint params to try\n",
        "    fp = plf.Fingerprint(interactions=[\n",
        "        \"Hydrophobic\", \"HBDonor\", \"HBAcceptor\", \"PiStacking\",\n",
        "        \"Anionic\", \"Cationic\", \"CationPi\", \"PiCation\",\n",
        "        \"VdWContact\",\n",
        "        \"XBDonor\", \"XBAcceptor\",\n",
        "        \"MetalDonor\", \"MetalAcceptor\"\n",
        "    ])\n",
        "    lig_files = {\"Boltz\": boltz_h_sdf, \"GNINA\": gnina_h_sdf}\n",
        "    html_outputs = []\n",
        "\n",
        "    for name, fpath in lig_files.items():\n",
        "        try:\n",
        "            suppl = Chem.SDMolSupplier(str(fpath), removeHs=False)\n",
        "            lig_mol = suppl[0]\n",
        "            # fix Resname for plot\n",
        "            for atom in lig_mol.GetAtoms():\n",
        "                mi = Chem.AtomPDBResidueInfo()\n",
        "                mi.SetResidueName(\"LIG\")\n",
        "                mi.SetResidueNumber(1)\n",
        "                mi.SetIsHeteroAtom(True)\n",
        "                atom.SetMonomerInfo(mi)\n",
        "\n",
        "            lig = plf.Molecule.from_rdkit(lig_mol)\n",
        "\n",
        "            # try run\n",
        "            fp.run_from_iterable([lig], prot)\n",
        "            df = fp.to_dataframe()\n",
        "\n",
        "            csv_path = RUN_DIR / \"analysis\" / f\"prolif_{name.lower()}_ifp.csv\"\n",
        "            html_path = RUN_DIR / \"analysis\" / f\"prolif_{name.lower()}.html\"\n",
        "\n",
        "            if df.empty or (df.shape[1] == 0):\n",
        "                print(f\"  {name}: No interactions found (even VdW). Check geometry.\")\n",
        "                html_outputs.append(f\"<div style='flex:1; border:1px solid red; padding:10px;'><h4>{name}</h4><p>No interactions detected.</p></div>\")\n",
        "            else:\n",
        "                df.to_csv(csv_path)\n",
        "                net = fp.plot_lignetwork(ligand_mol=lig, kind=\"frame\", frame=0)\n",
        "                net.save(str(html_path))\n",
        "                src = html.escape(Path(html_path).read_text())\n",
        "                html_outputs.append(f\"\"\"\n",
        "                <div style=\"flex: 1; border: 1px solid #ccc; padding: 5px;\">\n",
        "                  <h4 style=\"text-align:center;\">{name} Pose</h4>\n",
        "                  <iframe srcdoc=\"{src}\" width=\"100%\" height=\"600px\" style=\"border:none;\"></iframe>\n",
        "                </div>\"\"\")\n",
        "                print(f\"  {name}: Success! ({int(df.sum(axis=1).sum())} interactions)\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  {name} failed: {e}\")\n",
        "            html_outputs.append(f\"<div style='flex:1;'><h4>{name} Error</h4><p>{e}</p></div>\")\n",
        "\n",
        "    display(HTML(f'<div style=\"display: flex; flex-direction: row; gap: 20px; width: 100%;\">{ \"\".join(html_outputs) }</div>'))\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"CRITICAL ProLIF ERROR: {e}\")\n",
        "\n",
        "# --- debugging neighborhood check ---\n",
        "#def count_contacts(lig_p):\n",
        "#    try:\n",
        "        #tmp = lig_p.parent / (lig_p.stem + \"_tmp.pdb\")\n",
        "        #run_cmd(f\"obabel -isdf {lig_p} -opdb -O {tmp}\", hlog)\n",
        "        #u_p = mda.Universe(str(receptor_pdb))\n",
        "        #u_l = mda.Universe(str(tmp))\n",
        "        #d = mda.lib.distances.distance_array(u_l.atoms.positions, u_p.select_atoms(\"protein\").positions)\n",
        "        #return len(u_p.select_atoms(\"protein\")[np.any(d < CONTACT_CUTOFF_A, axis=0)].residues)\n",
        "    #except: return -1\n",
        "\n",
        "#print(f\"\\nResidues within {CONTACT_CUTOFF_A} Å:\")\n",
        "#print(f\"  Boltz : {count_contacts(boltz_pose_sdf)}\")\n",
        "#print(f\"  GNINA : {count_contacts(best_pose_sdf)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zLR3bfhO46Ws",
      "metadata": {
        "id": "zLR3bfhO46Ws"
      },
      "source": [
        "## **I. Export results**\n",
        "\n",
        "Compress the project folder (structures, SDFs, CSVs, logs).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99p9TOGT46Ws",
      "metadata": {
        "cellView": "form",
        "id": "99p9TOGT46Ws"
      },
      "outputs": [],
      "source": [
        "#@title **I1) Export project folder**\n",
        "#@markdown Choose what to export, then choose compression format.\n",
        "\n",
        "EXPORT_SCOPE = \"full_project\" #@param [\"current_run\", \"full_project\"]\n",
        "COMPRESSION_FORMAT = \"zip\" #@param [\"zip\", \"tar\", \"gztar\"]\n",
        "\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "# --- project-level name ---\n",
        "try:\n",
        "    PROJECT_NAME\n",
        "except NameError:\n",
        "    # best-effort fallback\n",
        "    PROJECT_NAME = Path(PROJECT_ROOT).name if \"PROJECT_ROOT\" in globals() else \"cloudbind_project\"\n",
        "\n",
        "ext_map = {\"zip\": \"zip\", \"tar\": \"tar\", \"gztar\": \"tar.gz\"}\n",
        "ext = ext_map.get(COMPRESSION_FORMAT, \"zip\")\n",
        "\n",
        "if EXPORT_SCOPE == \"current_run\":\n",
        "    root_dir = RUN_DIR.parent\n",
        "    base_dir = RUN_DIR.name\n",
        "    out_base = Path(\"/content\") / f\"{RUN_NAME}_run\"\n",
        "    what = f\"run folder: {RUN_DIR}\"\n",
        "else:\n",
        "    root_dir = PROJECT_ROOT\n",
        "    base_dir = None\n",
        "    out_base = Path(\"/content\") / f\"{PROJECT_NAME}_full_project\"\n",
        "    what = f\"full project: {PROJECT_ROOT}\"\n",
        "\n",
        "archive_path = Path(f\"{out_base}.{ext}\")\n",
        "\n",
        "if archive_path.exists():\n",
        "    archive_path.unlink()\n",
        "\n",
        "print(f\"Compressing {what} -> {archive_path} ...\")\n",
        "\n",
        "if base_dir is None:\n",
        "    shutil.make_archive(str(out_base), COMPRESSION_FORMAT, root_dir=str(root_dir))\n",
        "else:\n",
        "    shutil.make_archive(str(out_base), COMPRESSION_FORMAT, root_dir=str(root_dir), base_dir=str(base_dir))\n",
        "\n",
        "if archive_path.exists():\n",
        "    sz_mb = archive_path.stat().st_size / (1024 * 1024)\n",
        "    print(f\"Created: {archive_path}\")\n",
        "    print(f\"Size   : {sz_mb:.2f} MB\")\n",
        "else:\n",
        "    print(\"Error: Archive creation failed.\")\n",
        "\n",
        "# download prompt\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download(str(archive_path))\n",
        "except Exception:\n",
        "    print(\"(Download is available in Colab only. Check the Files sidebar if the prompt doesn't appear.)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YIy1emaWmq1k",
      "metadata": {
        "id": "YIy1emaWmq1k"
      },
      "source": [
        "## **M. Manifest (Optional)**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sW554gUTmq1k",
      "metadata": {
        "cellView": "form",
        "id": "sW554gUTmq1k"
      },
      "outputs": [],
      "source": [
        "#@title **M1) Write a manifest for reproducibility and debugging**\n",
        "\n",
        "import json, platform, subprocess, datetime\n",
        "from pathlib import Path\n",
        "\n",
        "manifest = {\n",
        "    \"timestamp\": datetime.datetime.now().isoformat(),\n",
        "    \"project_root\": str(PROJECT_ROOT),\n",
        "    \"run_name\": RUN_NAME if \"RUN_NAME\" in globals() else None,\n",
        "    \"run_dir\": str(RUN_DIR) if \"RUN_DIR\" in globals() else None,\n",
        "    \"tools_dir\": str(TOOLS_DIR),\n",
        "    \"versions\": {\n",
        "        \"boltz\": BOLTZ_VERSION,\n",
        "        \"p2rank\": P2RANK_VERSION,\n",
        "        \"gnina\": GNINA_VERSION,\n",
        "        \"python\": platform.python_version(),\n",
        "    },\n",
        "}\n",
        "\n",
        "# hardware info\n",
        "try:\n",
        "    import torch\n",
        "    if torch.cuda.is_available():\n",
        "        manifest[\"gpu\"] = torch.cuda.get_device_name(0)\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "def tail_text(p: Path, n=40):\n",
        "    if not p.exists():\n",
        "        return None\n",
        "    lines = p.read_text(errors=\"ignore\").splitlines()\n",
        "    return \"\\n\".join(lines[-n:])\n",
        "\n",
        "if \"RUN_DIR\" in globals():\n",
        "    log_dir = RUN_DIR / \"logs\"\n",
        "    manifest[\"log_tails\"] = {\n",
        "        p.name: tail_text(p, n=40) for p in sorted(log_dir.glob(\"*.log\"))\n",
        "    }\n",
        "    # expected files\n",
        "    expected = [\n",
        "        RUN_DIR / \"analysis\" / \"boltz_complex.pdb\",\n",
        "        RUN_DIR / \"analysis\" / \"receptor.pdb\",\n",
        "        RUN_DIR / \"analysis\" / \"boltz_ligand_pose.pdb\",\n",
        "        RUN_DIR / \"analysis\" / \"boltz_ligand_pose.sdf\",\n",
        "        RUN_DIR / \"analysis\" / \"boltz_affinity.json\",\n",
        "        RUN_DIR / \"analysis\" / \"gnina_modes.csv\",\n",
        "    ]\n",
        "    manifest[\"artifact_exists\"] = {str(p): p.exists() for p in expected}\n",
        "\n",
        "out_path = (RUN_DIR / \"analysis\" / f\"manifest_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.json\") if \"RUN_DIR\" in globals() else (PROJECT_ROOT / \"manifest.json\")\n",
        "Path(out_path).write_text(json.dumps(manifest, indent=2))\n",
        "print(f\"Wrote: {out_path}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
